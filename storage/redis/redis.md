# Redis 常用知识点:
## Redis的数据结构：
redis总共有五种常用数据类型，key对象都是string，value对象可能是string、list、hashmap、set以及sorted set;  
根据数据size的不同，底层实现的方式可能有所不同

### 字符串对象:
日常项目中，最常用的对象无非就是字符串对象，用来作为某些对象的缓存或者某些简单的计算  
字符串的底层实现分为三种：
1. int类型，当存储内容为整型或者long类型的整数时，由于整数占用空间小，因此直接存储在对象内，不需要额外空间；同时方便频繁的数字计算
2. embstr类型，当存储的字符串的长度小于某个阈值(不同版本不一样咯)，即该redis对象为一块连续完整的内存，对象基本信息之后紧跟一个sds对象
3. raw类型，redis对象里存有一个指向sds内存块的指针

#### int类型：
当存储对象是整型或long类型的整数时，一般会按照int编码的方式进行存储，整型一般为1～4个字节，占用空间小，无需额外存储分配，直接存入对象即可；  
同时，执行INCR等命令时，无需转换为字符串，直接进行整型计算，减少了类型转换的开销；

##### 当存储对象为浮点数或者字符串的时候，底层会用紧凑型字符串(embstr)或者原生的字节数组(raw)，由对象大小决定
#### embstr类型：
set一个字符串键时，根据字符串的长度决定编码类型，当字符串对象较小时，redis会为该对象分配一块连续的内存(对象类型，编码类型以及存储内容的sds)
#### raw类型：
当embstr对象超过了阈值或对象初始大小较大时，redis会为该对象分配两块内存，一块是存有字符串内容的sds，另一块则是redis对象并指向对应的sds

##### embstr相比于raw，内存分配和内存释放的次数各少了一次，减少内存操作意味着减少系统调用从而提升命令执行的效率；同时减少因额外分配空间释放导致的内存碎片
##### 同时连续的内存空间，无用额外寻址；因此可以方便利用缓存的特性，进一步优化查询性能(当然我觉得这块差别很微小)

### 列表对象：
列表对象指对应的键存有一系列对象，底层是由ziplist或者linkedlist实现
#### ziplist:
当列表内元素大小较小并且总的元素个数比较少的时候，列表对象会分配一块连续的内存存储列表对象及其元素对象们  
ziplist可看作编程语言中的数组，对象之间的内存连续
```
type ziplist struct {
    zlbytes int // 该字段用来存储ziplist总共占据内存多少字节空间
    zltail int //  尾指针，主要代表该ziplist内存起始地址到尾节点之间的偏移字节
    zllen int // 长度，即元素个数
    content []zipnode 指向具体元素存储的内存，是一个compacted array
    zlend int // 结束字节
}

type zipnode struct {
    previous_entry_size 1个字节或者5个字节 // 用来描述该节点的前一节点的内存大小，使得尾节点可以向前索引  
    encoding_type // 长度为1，2或者5字节，当该字段仅一个字段时，该entry内存的元素是整型元素；若为2或5字节，则该entry内存的事字节数组，同时包含数组的长度
    content // 具体内容
}
```
从上面ziplist的结构可以看出，每个node是一个可能变化的结构，比如LPUSH、LPOP，从列表头插入或者删除一个元素，那么每个节点的previous_entry_size可能都会发生变化，那么相应节点的内存以及后续节点的位置都需要移动，
极端情况下，每个元素的previous_entry_size都发生变化，整体的时间复杂度会退化到O(N^2)

#### linkedlist:
当元素大小较大或者元素个数较多时，ziplist会升级为双向链表，链表中每个对象都是一个string对象，如上所述

### 哈希对象：
哈希对象底层实现是ziplist或者dict字典，压缩列表的结构上面已经介绍过了，只不过哈希对象会按照键值对一个键和一个值交替存入压缩列表
#### dict实现：
当元素比较多且元素大小比较大时，redis会使用字典对哈希对象进行编码实现，采用seperate chaining的方式，字典内持有两个hashmap，一般情况下只使用第一个，
当正在进行rehash时，另一个hashmap才会使用  
seperate chaining 这个rehash的策略很熟悉了，就不再赘述了；而渐进式的rehash过程跟之前在golang内学习map的方式几乎一样，所以也不再多花时间了

### 集合对象：
普通的集合对象根据元素类型和元素数目决定底层实现是intset(整数集合)or hashmap
#### intset：
若该集合内的元素都为整数且元素数目较少时，会使用整型集合作为底层实现
```
type intset struct {
    encoding uint32 // 整型元素的编码方式，决定底层数组的元素类型是int16, int32还是int64
    length uint32 // 当前集合数组的长度
    content []intxx // 集合数组，元素类型取决于encoding的方式，元素唯一且有序(为了唯一性判断方便，二分)    
}
```

如果元素类型为其他或者元素数目比较多时，底层会采用hashmap进行实现，只不过value存的是null对象

### 有序集合对象：
底层实现是ziplist或者skiplist，如果是ziplist，content则会存集合的元素及其分数值
如果是skiplist的实现方式，zset内会包含一个字典以及跳表
```
type zset struct {
    skiplist // 用logN的复杂度索引到指定的集合元素
    dict // 字典主要是为根据分数快速索引到集合对象
}
```
如果用普通的列表+实时的排序实现有序集合，则每次插入新的元素之后都要用快排对列表进行重排序  
插入元素：时间复杂度是O(NlogN)，空间复杂度为O(logN);   
查询对象: 二分查找也可将查询复杂度控制在O(logN);  
移除元素：平移动剩下的元素，平均时间复杂度为O(N)

##### 那么跳表相比于普通列表的优势在哪？

跳表的本质是在有序列表上建立多级索引，假设链表的长度为N且每两个节点之间抽一个索引，则一级索引的个数为N/2，二级索引为N/4，直到第k级索引为1  

那么总共多出来的索引节点个数为N/2 + N/4 + ...... + 1 = 2^k - 1，k=logN, 即结果为N-1，其实就是用额外的空间，将查询的时间复杂度优化为了O(logN)  

##### 跳表索引的建立和更新：  
程序在将元素插入到有序列表的同时，判断该索引等级是否需要添加索引，一般的方法(包括redis中zset的实现)，均为如下方法：  

第一层索引有N/2个索引，即每个元素作为第一层索引的概率为1/2；  
第二层索引有N/4个索引，即每个元素作为第二层索引的概率为1/4;  
第k层索引，即最高层，只有一个索引，那么某个元素成为该层索引的概率为1/2^k;  

这种方法最坏的情况就是插入元素需要在每层安排一个索引，那么先在对应层寻找索引要插入的位置，然后插入，时间复杂度为O(logN1+logN2 + ......+logN)，即O(logN)；

删除元素时，需要从最高层开始一直到存有元素对象的链表中，每层都先查询该元素是否存在索引，有则删除，删除索引复杂度也是一样

## redis + os
### redis的线程模型：
早期的redis是一个单线程模型，因为redis主要都是内存读写操作，执行十分迅速，因此cpu并非是瓶颈；

主要的瓶颈是在网络I/O的传输延时以及磁盘文件的持久化上，即I/0瓶颈，所以redis采用了单线程+事件模型+I/O多路复用进行系统搭建

优点是
1. 由于单线程的设计，redis对内存的读写无需引入同步变量来处理竞态条件，且无需进行线程之间的切换，系统的性能进一步提升
2. I/O多路复用+异步执行的方式无阻塞，在一个事件循环内，epoll或者kqueue会轮询所有其下的socket套接字，当其可读或者可写，执行对应的事件逻辑

### I/O多路复用
#### 连接事件：  
server在启动的时候，会根据自己的ip:port生成一个server的socket接收其他client的连接请求；  
当server的socket有可读事件时，server进程内会创建新的socket用于client和server之间的通信；

#### 命令请求和相应事件：
当client发送命令请求redis server的执行，在事件循环中多路复用epoll或者kqueue，会监听所有的socket是否可操作；  
当socket可操作时，说明缓冲区内读写内容已经ready，进行命令的操作以及对client的响应

## redis的持久化
redis的持久化主要有两种方式，一种是RDB，另外一种是AOF  
RDB是redis某个时刻内存的数据快照，AOF则是所有写命令的日志文件；server启动时，都可以借助二者进行数据的恢复

### RDB(数据快照)
RDB是redis某个时刻的内存数据快照，同server最新的数据是有差距的，因此从数据一致性的角度，RDB可能会有数据的缺失

RDB文件的生成有两种方式一种是停机生成(SAVE)，另一种是后台生成(BGSAVE);

SAVE是停机生成RDB文件，因此该方法生成的快照即是最新的，但是停机对用户使用的影响比较大，一般很少使用

BGSAVE是主进程fork一个子进程出来，采用写时复制的方式：
1. 起初两个进程共享内存存储；  
2. 当主进程继续接收写命令，对某些内存进行修改，根据写时复制，有修改的这部分内存页会进行复制，然后修改复制的副本； 
3. 待RDB文件重写完成，子进程结束，子进程信号通知主进程并替换RDB文件

从写时复制的过程能看到，RDB是上一次fork的数据快照，fork进程到进程结束之间的写命令没有被存下来，因此当server宕机，之后在用RDB进行数据恢复时，这部分命令会丢失掉

因此RDB一般用于主从架构中，从服务器从对应的主服务器获取对应的RDB文件然后进行数据初始化，增量的命令通过命令连接进行通信

### AOF(写命令的日志)
AOF是写命令的日志集合，每当执行一行写命令之后，server会将该命令按照指定协议格式写入AOF缓冲区，每轮事件循环按照指定的策略写入AOF文件

一般有三种AOF写入策略：
1. always：将AOF缓冲区内的内容写入并同步到AOF文件内
2. everyseconds: 将AOF缓冲区内的内容写入文件内，如果上次AOF文件同步的时间超过1s，redis会将文件缓冲的内容刷入磁盘文件
3. no:将AOF缓冲区内的内容写入文件内，但是不进行同步，同步是由操作系统决定

always数据一致性最高，但是性能也是要求最高的，因为每轮事件循环都需要进行中断刷盘  
everyseconds是一个较为全面的选择；no则可能会将数据堆在fd内的缓冲区内，导致数据丢失

随着系统的运行，AOF文件会越来越大，加载和维护的系统成本也越来越大，因此需要根据当前的内存数据，对AOF进行重写，精简文件内容，因此需要AOF重写

#### AOF重写
AOF重写(BGSAVEAOF)：也是fork一个子进程，采用写时复制进行重写
1. 子进程将当前内存内容，按照写命令进行重写，比如某个list对象内包含3，4，5三个元素，历史操作可能很多很多，但是重写只会以一条或者多条命令记录，比如`lpush key 3，4，5`
2. 主进程继续接收命令提供服务，但是写命令会写入一个AOF重写缓冲区，记录增量命令
3. 子进程通知主进程重写完成，此时主进程会短暂停机一小会儿，便于缓冲区内容append到新aof文件后面，并进行文件替换
4. 主进程恢复

### 这块有个操作系统的概念，需要和redis本身的设计区分开来  

对于read和write这类系统调用来说，其实文件描述符也是有对应的缓存区的，并不是write 16bytes就是立马完成的

当某个fd的写缓冲区已满，因此新的内容无法写入，此时线程会阻塞等待直到缓冲区内容同步写入文件，然后将新的内容写入缓冲区完成；

当程序读取某个fd，但此时可读缓冲区内容不足n bytes，那么线程会阻塞直到缓冲区内容满足n bytes，并将内容读出

#### 这里则有个关于非阻塞I/O和异步I/O的概念
非阻塞I/O: 当I/O操作没有满足执行条件，比如读缓冲内容不足，那么该I/O并不会阻塞而是不执行返回给调用方，一般需要程序或者事件模型轮询维护，eg. epoll

异步I/0: 类似于异步RPC，调用处可继续执行后续程序，当该I/O执行完成后，通过信号或者通信告诉线程

## redis的分布式架构

## redis缓存